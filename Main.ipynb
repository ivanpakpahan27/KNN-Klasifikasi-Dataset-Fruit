{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xpx8anWaspz4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BDyA_NR6_KVV"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_train  = pd.read_csv(\"flower_dataset_features.csv\")\n",
    "data_train  = data_train.iloc[:,0:1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_991</th>\n",
       "      <th>feature_992</th>\n",
       "      <th>feature_993</th>\n",
       "      <th>feature_994</th>\n",
       "      <th>feature_995</th>\n",
       "      <th>feature_996</th>\n",
       "      <th>feature_997</th>\n",
       "      <th>feature_998</th>\n",
       "      <th>feature_999</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.705626</td>\n",
       "      <td>1.639594</td>\n",
       "      <td>0.172473</td>\n",
       "      <td>0.969996</td>\n",
       "      <td>1.642890</td>\n",
       "      <td>1.569268</td>\n",
       "      <td>3.220661</td>\n",
       "      <td>-0.930843</td>\n",
       "      <td>-0.801508</td>\n",
       "      <td>-0.791831</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.080458</td>\n",
       "      <td>-0.836896</td>\n",
       "      <td>-3.084549</td>\n",
       "      <td>-1.443821</td>\n",
       "      <td>-1.061417</td>\n",
       "      <td>-1.024025</td>\n",
       "      <td>-1.334315</td>\n",
       "      <td>-0.435808</td>\n",
       "      <td>3.960737</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.919001</td>\n",
       "      <td>1.232931</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.847642</td>\n",
       "      <td>1.559437</td>\n",
       "      <td>1.509283</td>\n",
       "      <td>3.097852</td>\n",
       "      <td>-0.977383</td>\n",
       "      <td>-0.736290</td>\n",
       "      <td>-0.511645</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.084081</td>\n",
       "      <td>-1.055354</td>\n",
       "      <td>-2.932213</td>\n",
       "      <td>-1.345144</td>\n",
       "      <td>-0.909128</td>\n",
       "      <td>-0.990325</td>\n",
       "      <td>-1.265927</td>\n",
       "      <td>-0.624571</td>\n",
       "      <td>3.888879</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.271701</td>\n",
       "      <td>1.200205</td>\n",
       "      <td>-0.213998</td>\n",
       "      <td>0.575831</td>\n",
       "      <td>1.145925</td>\n",
       "      <td>0.856601</td>\n",
       "      <td>2.387752</td>\n",
       "      <td>-1.246825</td>\n",
       "      <td>-1.232825</td>\n",
       "      <td>-1.000458</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.456583</td>\n",
       "      <td>-1.268389</td>\n",
       "      <td>-3.221443</td>\n",
       "      <td>-1.661749</td>\n",
       "      <td>-1.422148</td>\n",
       "      <td>-1.275681</td>\n",
       "      <td>-1.748431</td>\n",
       "      <td>-0.771336</td>\n",
       "      <td>3.898668</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.831656</td>\n",
       "      <td>1.348944</td>\n",
       "      <td>0.080967</td>\n",
       "      <td>0.760328</td>\n",
       "      <td>1.455922</td>\n",
       "      <td>1.421007</td>\n",
       "      <td>3.017863</td>\n",
       "      <td>-0.900549</td>\n",
       "      <td>-0.705898</td>\n",
       "      <td>-0.533548</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.110439</td>\n",
       "      <td>-1.028517</td>\n",
       "      <td>-3.130740</td>\n",
       "      <td>-1.555300</td>\n",
       "      <td>-1.092949</td>\n",
       "      <td>-1.004328</td>\n",
       "      <td>-1.410209</td>\n",
       "      <td>-0.568221</td>\n",
       "      <td>3.876160</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.682855</td>\n",
       "      <td>1.434426</td>\n",
       "      <td>0.416150</td>\n",
       "      <td>1.064780</td>\n",
       "      <td>1.796767</td>\n",
       "      <td>1.819750</td>\n",
       "      <td>3.463787</td>\n",
       "      <td>-0.854703</td>\n",
       "      <td>-0.482591</td>\n",
       "      <td>-0.456361</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.974737</td>\n",
       "      <td>-0.978553</td>\n",
       "      <td>-2.942863</td>\n",
       "      <td>-1.470003</td>\n",
       "      <td>-1.005337</td>\n",
       "      <td>-0.953264</td>\n",
       "      <td>-1.321891</td>\n",
       "      <td>-0.709360</td>\n",
       "      <td>3.813428</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>-0.788711</td>\n",
       "      <td>1.318606</td>\n",
       "      <td>0.359343</td>\n",
       "      <td>1.028531</td>\n",
       "      <td>1.730650</td>\n",
       "      <td>1.665701</td>\n",
       "      <td>3.299466</td>\n",
       "      <td>-0.762547</td>\n",
       "      <td>-0.508561</td>\n",
       "      <td>-0.471621</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.075481</td>\n",
       "      <td>-1.045255</td>\n",
       "      <td>-2.934833</td>\n",
       "      <td>-1.524112</td>\n",
       "      <td>-1.123691</td>\n",
       "      <td>-1.062733</td>\n",
       "      <td>-1.342577</td>\n",
       "      <td>-0.792613</td>\n",
       "      <td>3.849834</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>-0.701194</td>\n",
       "      <td>1.628309</td>\n",
       "      <td>0.176184</td>\n",
       "      <td>0.900150</td>\n",
       "      <td>1.627900</td>\n",
       "      <td>1.691826</td>\n",
       "      <td>3.266127</td>\n",
       "      <td>-1.000329</td>\n",
       "      <td>-0.685306</td>\n",
       "      <td>-0.742335</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.073668</td>\n",
       "      <td>-0.878486</td>\n",
       "      <td>-3.071159</td>\n",
       "      <td>-1.481170</td>\n",
       "      <td>-0.989276</td>\n",
       "      <td>-0.872868</td>\n",
       "      <td>-1.262147</td>\n",
       "      <td>-0.463600</td>\n",
       "      <td>4.092826</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>-0.836027</td>\n",
       "      <td>1.067055</td>\n",
       "      <td>0.089245</td>\n",
       "      <td>0.910240</td>\n",
       "      <td>1.737288</td>\n",
       "      <td>1.706021</td>\n",
       "      <td>3.138594</td>\n",
       "      <td>-0.795321</td>\n",
       "      <td>-0.420847</td>\n",
       "      <td>-0.291222</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.997577</td>\n",
       "      <td>-1.027216</td>\n",
       "      <td>-2.878318</td>\n",
       "      <td>-1.455801</td>\n",
       "      <td>-0.881730</td>\n",
       "      <td>-0.903243</td>\n",
       "      <td>-1.238593</td>\n",
       "      <td>-0.823124</td>\n",
       "      <td>3.872625</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>-0.502455</td>\n",
       "      <td>1.651924</td>\n",
       "      <td>0.360176</td>\n",
       "      <td>1.156204</td>\n",
       "      <td>1.955855</td>\n",
       "      <td>2.181633</td>\n",
       "      <td>3.797047</td>\n",
       "      <td>-0.705094</td>\n",
       "      <td>-0.290442</td>\n",
       "      <td>-0.625256</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.747128</td>\n",
       "      <td>-0.713329</td>\n",
       "      <td>-2.840251</td>\n",
       "      <td>-1.402702</td>\n",
       "      <td>-0.817473</td>\n",
       "      <td>-0.646354</td>\n",
       "      <td>-1.151632</td>\n",
       "      <td>-0.523780</td>\n",
       "      <td>4.012846</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>-0.710914</td>\n",
       "      <td>1.137711</td>\n",
       "      <td>0.297860</td>\n",
       "      <td>1.104632</td>\n",
       "      <td>1.907295</td>\n",
       "      <td>1.871737</td>\n",
       "      <td>3.290599</td>\n",
       "      <td>-0.739640</td>\n",
       "      <td>-0.404090</td>\n",
       "      <td>-0.401938</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.037861</td>\n",
       "      <td>-1.091384</td>\n",
       "      <td>-2.863522</td>\n",
       "      <td>-1.383927</td>\n",
       "      <td>-0.905677</td>\n",
       "      <td>-0.983721</td>\n",
       "      <td>-1.244687</td>\n",
       "      <td>-0.960679</td>\n",
       "      <td>3.864244</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4272 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0     -0.705626   1.639594   0.172473   0.969996   1.642890   1.569268   \n",
       "1     -0.919001   1.232931   0.085981   0.847642   1.559437   1.509283   \n",
       "2     -1.271701   1.200205  -0.213998   0.575831   1.145925   0.856601   \n",
       "3     -0.831656   1.348944   0.080967   0.760328   1.455922   1.421007   \n",
       "4     -0.682855   1.434426   0.416150   1.064780   1.796767   1.819750   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4267  -0.788711   1.318606   0.359343   1.028531   1.730650   1.665701   \n",
       "4268  -0.701194   1.628309   0.176184   0.900150   1.627900   1.691826   \n",
       "4269  -0.836027   1.067055   0.089245   0.910240   1.737288   1.706021   \n",
       "4270  -0.502455   1.651924   0.360176   1.156204   1.955855   2.181633   \n",
       "4271  -0.710914   1.137711   0.297860   1.104632   1.907295   1.871737   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_991  \\\n",
       "0      3.220661  -0.930843  -0.801508  -0.791831  ...    -2.080458   \n",
       "1      3.097852  -0.977383  -0.736290  -0.511645  ...    -2.084081   \n",
       "2      2.387752  -1.246825  -1.232825  -1.000458  ...    -2.456583   \n",
       "3      3.017863  -0.900549  -0.705898  -0.533548  ...    -2.110439   \n",
       "4      3.463787  -0.854703  -0.482591  -0.456361  ...    -1.974737   \n",
       "...         ...        ...        ...        ...  ...          ...   \n",
       "4267   3.299466  -0.762547  -0.508561  -0.471621  ...    -2.075481   \n",
       "4268   3.266127  -1.000329  -0.685306  -0.742335  ...    -2.073668   \n",
       "4269   3.138594  -0.795321  -0.420847  -0.291222  ...    -1.997577   \n",
       "4270   3.797047  -0.705094  -0.290442  -0.625256  ...    -1.747128   \n",
       "4271   3.290599  -0.739640  -0.404090  -0.401938  ...    -2.037861   \n",
       "\n",
       "      feature_992  feature_993  feature_994  feature_995  feature_996  \\\n",
       "0       -0.836896    -3.084549    -1.443821    -1.061417    -1.024025   \n",
       "1       -1.055354    -2.932213    -1.345144    -0.909128    -0.990325   \n",
       "2       -1.268389    -3.221443    -1.661749    -1.422148    -1.275681   \n",
       "3       -1.028517    -3.130740    -1.555300    -1.092949    -1.004328   \n",
       "4       -0.978553    -2.942863    -1.470003    -1.005337    -0.953264   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4267    -1.045255    -2.934833    -1.524112    -1.123691    -1.062733   \n",
       "4268    -0.878486    -3.071159    -1.481170    -0.989276    -0.872868   \n",
       "4269    -1.027216    -2.878318    -1.455801    -0.881730    -0.903243   \n",
       "4270    -0.713329    -2.840251    -1.402702    -0.817473    -0.646354   \n",
       "4271    -1.091384    -2.863522    -1.383927    -0.905677    -0.983721   \n",
       "\n",
       "      feature_997  feature_998  feature_999      class  \n",
       "0       -1.334315    -0.435808     3.960737      daisy  \n",
       "1       -1.265927    -0.624571     3.888879      daisy  \n",
       "2       -1.748431    -0.771336     3.898668      daisy  \n",
       "3       -1.410209    -0.568221     3.876160      daisy  \n",
       "4       -1.321891    -0.709360     3.813428      daisy  \n",
       "...           ...          ...          ...        ...  \n",
       "4267    -1.342577    -0.792613     3.849834  sunflower  \n",
       "4268    -1.262147    -0.463600     4.092826  sunflower  \n",
       "4269    -1.238593    -0.823124     3.872625  sunflower  \n",
       "4270    -1.151632    -0.523780     4.012846  sunflower  \n",
       "4271    -1.244687    -0.960679     3.864244  sunflower  \n",
       "\n",
       "[4272 rows x 1001 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train     = data_train.iloc[:,0:1000].values\n",
    "y_train     = data_train.iloc[:,-1:].values\n",
    "row,coloumn = x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['daisy'],\n",
       "       ['daisy'],\n",
       "       ['daisy'],\n",
       "       ...,\n",
       "       ['sunflower'],\n",
       "       ['sunflower'],\n",
       "       ['sunflower']], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7AKNqh6Bxv1",
    "outputId": "7fe43c84-48aa-4f92-f9bc-7d7e15435450"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3_7\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Encoding\n",
    "# x\n",
    "for i in range(coloumn):\n",
    "    x_train[: , i] = LabelEncoder().fit_transform(x_train[:,i])\n",
    "# y\n",
    "y_train            = LabelEncoder().fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3Q7et2iQ5B8",
    "outputId": "c6dd5c5e-b7b2-4cf3-d981-0514f39815cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4264.0, 4263.0, 4266.0, 4265.0, 4264.0, 4266.0, 4265.0, 4262.0, 4265.0, 4263.0, 4265.0, 4265.0, 4266.0, 4266.0, 4266.0, 4266.0, 4266.0, 4265.0, 4266.0, 4264.0, 4264.0, 4264.0, 4265.0, 4265.0, 4263.0, 4263.0, 4266.0, 4265.0, 4265.0, 4264.0, 4265.0, 4266.0, 4265.0, 4265.0, 4262.0, 4264.0, 4265.0, 4265.0, 4260.0, 4266.0, 4266.0, 4266.0, 4263.0, 4266.0, 4264.0, 4257.0, 4265.0, 4266.0, 4266.0, 4266.0, 4266.0, 4266.0, 4259.0, 4265.0, 4262.0, 4266.0, 4259.0, 4263.0, 4253.0, 4265.0, 4259.0, 4264.0, 4266.0, 4262.0, 4264.0, 4262.0, 4265.0, 4259.0, 4264.0, 4266.0, 4266.0, 4261.0, 4265.0, 4265.0, 4266.0, 4257.0, 4263.0, 4262.0, 4263.0, 4260.0, 4264.0, 4262.0, 4266.0, 4264.0, 4266.0, 4264.0, 4264.0, 4264.0, 4265.0, 4265.0, 4263.0, 4266.0, 4265.0, 4266.0, 4266.0, 4263.0, 4266.0, 4265.0, 4266.0, 4266.0, 4265.0, 4265.0, 4264.0, 4262.0, 4266.0, 4263.0, 4266.0, 4264.0, 4266.0, 4266.0, 4265.0, 4263.0, 4263.0, 4266.0, 4265.0, 4259.0, 4265.0, 4263.0, 4265.0, 4266.0, 4264.0, 4263.0, 4260.0, 4266.0, 4266.0, 4265.0, 4264.0, 4266.0, 4265.0, 4265.0, 4265.0, 4266.0, 4264.0, 4266.0, 4264.0, 4266.0, 4262.0, 4263.0, 4265.0, 4266.0, 4266.0, 4265.0, 4264.0, 4263.0, 4266.0, 4266.0, 4266.0, 4263.0, 4263.0, 4265.0, 4266.0, 4265.0, 4266.0, 4263.0, 4262.0, 4266.0, 4264.0, 4265.0, 4265.0, 4261.0, 4266.0, 4264.0, 4261.0, 4265.0, 4266.0, 4263.0, 4265.0, 4263.0, 4262.0, 4266.0, 4266.0, 4262.0, 4262.0, 4265.0, 4265.0, 4263.0, 4266.0, 4264.0, 4266.0, 4266.0, 4265.0, 4266.0, 4266.0, 4263.0, 4265.0, 4262.0, 4266.0, 4263.0, 4265.0, 4265.0, 4266.0, 4260.0, 4265.0, 4264.0, 4266.0, 4263.0, 4266.0, 4262.0, 4260.0, 4266.0, 4264.0, 4258.0, 4266.0, 4263.0, 4266.0, 4259.0, 4262.0, 4266.0, 4266.0, 4262.0, 4265.0, 4261.0, 4264.0, 4264.0, 4261.0, 4264.0, 4266.0, 4265.0, 4266.0, 4266.0, 4260.0, 4263.0, 4266.0, 4265.0, 4261.0, 4266.0, 4266.0, 4263.0, 4266.0, 4261.0, 4266.0, 4266.0, 4265.0, 4264.0, 4264.0, 4262.0, 4263.0, 4264.0, 4266.0, 4265.0, 4260.0, 4265.0, 4264.0, 4266.0, 4265.0, 4265.0, 4266.0, 4266.0, 4266.0, 4265.0, 4264.0, 4265.0, 4264.0, 4266.0, 4265.0, 4263.0, 4261.0, 4266.0, 4261.0, 4265.0, 4265.0, 4265.0, 4258.0, 4262.0, 4266.0, 4265.0, 4264.0, 4265.0, 4264.0, 4265.0, 4266.0, 4266.0, 4266.0, 4264.0, 4264.0, 4266.0, 4264.0, 4266.0, 4265.0, 4262.0, 4266.0, 4265.0, 4266.0, 4264.0, 4265.0, 4265.0, 4266.0, 4266.0, 4266.0, 4266.0, 4263.0, 4266.0, 4265.0, 4265.0, 4265.0, 4266.0, 4266.0, 4265.0, 4264.0, 4265.0, 4266.0, 4263.0, 4265.0, 4266.0, 4266.0, 4265.0, 4265.0, 4266.0, 4265.0, 4263.0, 4260.0, 4266.0, 4262.0, 4262.0, 4264.0, 4266.0, 4266.0, 4266.0, 4263.0, 4264.0, 4266.0, 4265.0, 4264.0, 4262.0, 4266.0, 4261.0, 4262.0, 4264.0, 4266.0, 4266.0, 4265.0, 4266.0, 4266.0, 4265.0, 4266.0, 4262.0, 4266.0, 4266.0, 4266.0, 4262.0, 4265.0, 4266.0, 4265.0, 4266.0, 4265.0, 4266.0, 4266.0, 4264.0, 4266.0, 4266.0, 4266.0, 4266.0, 4265.0, 4265.0, 4266.0, 4266.0, 4263.0, 4265.0, 4264.0, 4263.0, 4265.0, 4266.0, 4264.0, 4263.0, 4265.0, 4261.0, 4263.0, 4265.0, 4263.0, 4260.0, 4264.0, 4265.0, 4266.0, 4266.0, 4265.0, 4263.0, 4264.0, 4265.0, 4265.0, 4263.0, 4265.0, 4264.0, 4264.0, 4266.0, 4265.0, 4266.0, 4266.0, 4263.0, 4263.0, 4265.0, 4266.0, 4263.0, 4255.0, 4266.0, 4265.0, 4266.0, 4265.0, 4266.0, 4265.0, 4265.0, 4264.0, 4259.0, 4263.0, 4264.0, 4264.0, 4264.0, 4265.0, 4264.0, 4264.0, 4263.0, 4264.0, 4266.0, 4263.0, 4266.0, 4265.0, 4265.0, 4265.0, 4262.0, 4263.0, 4265.0, 4265.0, 4264.0, 4265.0, 4265.0, 4264.0, 4266.0, 4266.0, 4266.0, 4265.0, 4266.0, 4265.0, 4263.0, 4263.0, 4264.0, 4259.0, 4265.0, 4258.0, 4266.0, 4266.0, 4261.0, 4263.0, 4265.0, 4266.0, 4262.0, 4263.0, 4260.0, 4264.0, 4264.0, 4266.0, 4262.0, 4265.0, 4266.0, 4265.0, 4265.0, 4255.0, 4266.0, 4265.0, 4266.0, 4264.0, 4265.0, 4265.0, 4266.0, 4266.0, 4262.0, 4262.0, 4265.0, 4266.0, 4255.0, 4263.0, 4265.0, 4266.0, 4266.0, 4260.0, 4266.0, 4265.0, 4266.0, 4262.0, 4264.0, 4260.0, 4261.0, 4260.0, 4265.0, 4264.0, 4260.0, 4264.0, 4266.0, 4262.0, 4266.0, 4266.0, 4263.0, 4262.0, 4261.0, 4264.0, 4265.0, 4265.0, 4265.0, 4265.0, 4265.0, 4264.0, 4265.0, 4265.0, 4262.0, 4265.0, 4265.0, 4264.0, 4266.0, 4266.0, 4266.0, 4266.0, 4260.0, 4266.0, 4262.0, 4265.0, 4263.0, 4262.0, 4266.0, 4263.0, 4265.0, 4266.0, 4260.0, 4260.0, 4266.0, 4265.0, 4266.0, 4264.0, 4264.0, 4266.0, 4264.0, 4265.0, 4260.0, 4265.0, 4265.0, 4263.0, 4266.0, 4265.0, 4265.0, 4262.0, 4266.0, 4264.0, 4265.0, 4266.0, 4263.0, 4266.0, 4265.0, 4266.0, 4264.0, 4263.0, 4258.0, 4264.0, 4263.0, 4264.0, 4258.0, 4263.0, 4262.0, 4263.0, 4261.0, 4263.0, 4265.0, 4265.0, 4266.0, 4264.0, 4262.0, 4260.0, 4264.0, 4266.0, 4266.0, 4259.0, 4265.0, 4264.0, 4263.0, 4266.0, 4266.0, 4265.0, 4266.0, 4265.0, 4263.0, 4262.0, 4264.0, 4265.0, 4265.0, 4266.0, 4259.0, 4260.0, 4265.0, 4266.0, 4264.0, 4266.0, 4265.0, 4260.0, 4265.0, 4265.0, 4261.0, 4266.0, 4263.0, 4262.0, 4266.0, 4266.0, 4264.0, 4264.0, 4266.0, 4265.0, 4265.0, 4266.0, 4263.0, 4264.0, 4263.0, 4263.0, 4261.0, 4265.0, 4266.0, 4263.0, 4265.0, 4261.0, 4266.0, 4261.0, 4265.0, 4265.0, 4264.0, 4265.0, 4264.0, 4266.0, 4265.0, 4262.0, 4264.0, 4263.0, 4265.0, 4265.0, 4265.0, 4264.0, 4266.0, 4266.0, 4261.0, 4266.0, 4265.0, 4264.0, 4266.0, 4266.0, 4265.0, 4262.0, 4264.0, 4266.0, 4264.0, 4264.0, 4264.0, 4264.0, 4261.0, 4265.0, 4263.0, 4265.0, 4266.0, 4266.0, 4265.0, 4265.0, 4264.0, 4262.0, 4265.0, 4265.0, 4266.0, 4266.0, 4265.0, 4263.0, 4259.0, 4265.0, 4265.0, 4265.0, 4265.0, 4265.0, 4263.0, 4265.0, 4264.0, 4263.0, 4260.0, 4264.0, 4263.0, 4263.0, 4264.0, 4264.0, 4266.0, 4265.0, 4265.0, 4260.0, 4266.0, 4265.0, 4264.0, 4266.0, 4266.0, 4265.0, 4264.0, 4266.0, 4266.0, 4264.0, 4265.0, 4265.0, 4265.0, 4263.0, 4266.0, 4264.0, 4266.0, 4261.0, 4264.0, 4263.0, 4262.0, 4266.0, 4259.0, 4265.0, 4260.0, 4264.0, 4266.0, 4266.0, 4265.0, 4265.0, 4266.0, 4264.0, 4265.0, 4262.0, 4266.0, 4265.0, 4261.0, 4265.0, 4265.0, 4266.0, 4263.0, 4265.0, 4264.0, 4263.0, 4264.0, 4264.0, 4266.0, 4264.0, 4264.0, 4266.0, 4262.0, 4265.0, 4264.0, 4266.0, 4266.0, 4265.0, 4264.0, 4266.0, 4262.0, 4261.0, 4265.0, 4265.0, 4264.0, 4265.0, 4265.0, 4265.0, 4266.0, 4260.0, 4263.0, 4261.0, 4265.0, 4266.0, 4262.0, 4265.0, 4263.0, 4265.0, 4265.0, 4264.0, 4265.0, 4264.0, 4265.0, 4253.0, 4266.0, 4266.0, 4266.0, 4262.0, 4262.0, 4266.0, 4265.0, 4263.0, 4264.0, 4264.0, 4264.0, 4264.0, 4262.0, 4261.0, 4264.0, 4264.0, 4265.0, 4265.0, 4263.0, 4264.0, 4264.0, 4265.0, 4265.0, 4266.0, 4265.0, 4265.0, 4265.0, 4264.0, 4266.0, 4264.0, 4263.0, 4260.0, 4266.0, 4263.0, 4265.0, 4264.0, 4264.0, 4252.0, 4266.0, 4263.0, 4266.0, 4265.0, 4266.0, 4266.0, 4264.0, 4262.0, 4266.0, 4264.0, 4266.0, 4261.0, 4265.0, 4265.0, 4264.0, 4263.0, 4261.0, 4266.0, 4262.0, 4263.0, 4260.0, 4262.0, 4264.0, 4263.0, 4265.0, 4265.0, 4266.0, 4264.0, 4253.0, 4262.0, 4259.0, 4266.0, 4263.0, 4266.0, 4264.0, 4265.0, 4266.0, 4262.0, 4264.0, 4264.0, 4265.0, 4261.0, 4263.0, 4266.0, 4264.0, 4265.0, 4264.0, 4265.0, 4265.0, 4265.0, 4265.0, 4265.0, 4264.0, 4262.0, 4259.0, 4265.0, 4265.0, 4266.0, 4266.0, 4260.0, 4264.0, 4266.0, 4262.0, 4264.0, 4258.0, 4264.0, 4265.0, 4263.0, 4265.0, 4264.0, 4263.0, 4266.0, 4265.0, 4251.0, 4264.0, 4264.0, 4264.0, 4263.0, 4265.0, 4262.0, 4265.0, 4266.0, 4265.0, 4260.0, 4266.0, 4263.0, 4266.0, 4262.0, 4265.0, 4266.0, 4266.0, 4262.0, 4263.0, 4265.0, 4264.0, 4263.0, 4266.0, 4264.0, 4260.0, 4266.0, 4264.0, 4266.0, 4265.0, 4262.0, 4265.0, 4264.0, 4266.0, 4259.0, 4264.0, 4264.0, 4264.0, 4263.0, 4266.0, 4266.0, 4266.0, 4264.0, 4264.0, 4261.0, 4266.0, 4263.0, 4259.0, 4260.0, 4265.0, 4265.0, 4266.0, 4261.0, 4264.0, 4266.0, 4266.0, 4264.0, 4266.0, 4265.0, 4264.0, 4261.0, 4263.0, 4265.0, 4266.0, 4266.0, 4261.0, 4264.0, 4262.0, 4264.0, 4266.0, 4258.0, 4265.0, 4264.0, 4266.0, 4266.0, 4265.0, 4262.0, 4262.0, 4266.0, 4266.0, 4265.0, 4263.0, 4265.0, 4264.0, 4265.0, 4265.0, 4264.0, 4262.0, 4259.0, 4261.0, 4260.0, 4265.0, 4265.0, 4265.0, 4266.0, 4265.0, 4264.0, 4264.0, 4266.0, 4261.0, 4266.0, 4264.0, 4265.0, 4264.0, 4264.0, 4264.0, 4265.0, 4265.0, 4266.0, 4262.0, 4263.0, 4265.0, 4264.0, 4265.0, 4266.0, 4262.0, 4262.0, 4262.0, 4263.0, 4260.0, 4264.0, 4262.0, 4265.0, 4261.0, 4265.0, 4261.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Normalize X\n",
    "maxx = []\n",
    "minn = []\n",
    "for i in range(coloumn):\n",
    "    maxx.append(np.max(x_train[:,i]))\n",
    "    minn.append(np.min(x_train[:,i]))\n",
    "print(maxx)\n",
    "print(minn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "u5vxYzi9rZWX"
   },
   "outputs": [],
   "source": [
    "# Normalize X\n",
    "for i in range(coloumn):  \n",
    "    for j in range(row):\n",
    "        x_train[j , i] = (x_train[j , i]- minn[i])/(maxx[i]-minn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7huEIX3rjcV",
    "outputId": "8f4c0989-9b33-498b-8c5e-83ebf196c92c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81496248, 0.98287591, 0.50046882, ..., 0.61229758, 0.96905041,\n",
       "        0.57826801],\n",
       "       [0.36280488, 0.37156932, 0.31340835, ..., 0.75545647, 0.69519343,\n",
       "        0.41328327],\n",
       "       [0.01055347, 0.29744312, 0.01851852, ..., 0.01126496, 0.29917937,\n",
       "        0.43769068],\n",
       "       ...,\n",
       "       [0.55722326, 0.08257096, 0.31879981, ..., 0.81389345, 0.2014068 ,\n",
       "        0.38042713],\n",
       "       [0.98452158, 0.9849871 , 0.86052508, ..., 0.93311429, 0.8883939 ,\n",
       "        0.68763201],\n",
       "       [0.8065197 , 0.16866057, 0.75738397, ..., 0.80262849, 0.03892145,\n",
       "        0.36141751]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "efHmRmPW-wao"
   },
   "outputs": [],
   "source": [
    "# Function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "sig = np.vectorize(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "kt5-NL4qqiZD"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------\n",
    "#- inisiasi\n",
    "\n",
    "input       = x_train\n",
    "target      = y_train\n",
    "num_input   = 1000\n",
    "net_hidden1 = 1000\n",
    "net_hidden2 = 1000\n",
    "num_output  = 1\n",
    "\n",
    "#Input-->Hidden Layer1\n",
    "w_hidden1 = np.random.uniform(low=-0.5, high=0.5, size=(num_input,net_hidden1))\n",
    "b_hidden1 = np.random.uniform(low=-0.5, high=0.5, size=(net_hidden1))\n",
    "#Hidden Layer1-->Hidden Layer2\n",
    "w_hidden2 = np.random.uniform(low=-0.5, high=0.5, size=(net_hidden1,net_hidden2))\n",
    "b_hidden2 = np.random.uniform(low=-0.5, high=0.5, size=(net_hidden2))\n",
    "#Hidden Layer2-->Output\n",
    "w_output = np.random.uniform(low=-0.5, high=0.5, size=(net_hidden2,num_output))\n",
    "b_output = np.random.uniform(low=-0.5, high=0.5, size=(num_output))\n",
    "\n",
    "# Loss dan Akurasi\n",
    "loss_values = []\n",
    "acc_values  = []\n",
    "\n",
    "lr     = 0.1\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvFlVTRi3BUl",
    "outputId": "222d7e54-7022-4b9c-e028-99af2154b802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(w_hidden1.shape)\n",
    "print(w_hidden2.shape)\n",
    "print(w_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9F3kurWvKtX",
    "outputId": "51dd8480-414c-458c-86d6-d9cf1f82a0ad"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-e50aadcb637e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mb_hidden2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb_hidden2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meh2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mo_hidden2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mo_hidden2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# Hidden Layer1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mw_hidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_hidden1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meh1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mo_hidden1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mo_hidden1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mb_hidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb_hidden1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meh1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mo_hidden1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mo_hidden1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_w_hidden1 = []\n",
    "list_w_hidden2 = []\n",
    "list_w_output  = []\n",
    "list_b_hidden1 = []\n",
    "list_b_hidden2 = []\n",
    "list_b_output  = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    MSE = 0\n",
    "    new_target = np.zeros(len(target))\n",
    "    for idx, inp in enumerate(input):\n",
    "        # A. Feedforward\n",
    "        # Hidden Layer1\n",
    "        o_hidden1 = np.matmul(input[idx], w_hidden1) + b_hidden1\n",
    "        o_hidden1 = sig(o_hidden1)\n",
    "        # Hidden Layer2\n",
    "        o_hidden2 = np.matmul(o_hidden1, w_hidden2) + b_hidden2\n",
    "        o_hidden2 = sig(o_hidden2)\n",
    "        # Outpur Layer\n",
    "        o_output  = np.matmul(o_hidden2, w_output) + b_output\n",
    "        o_output  = sig(o_output)\n",
    "        # Menghitung Error\n",
    "        error           = target[idx] - o_output\n",
    "        MSE             = MSE + (error*error)\n",
    "        new_target[idx] = o_output.round()\n",
    "        # Error hidden2->output\n",
    "        eh2             = error @ w_output.T\n",
    "        # Error hidden1->output \n",
    "        eh1             = eh2   @ w_hidden2.T\n",
    "        # B. Backpropagation\n",
    "        # Outpur Layer\n",
    "        w_output = w_output + (lr * ((error * o_output * (1 - o_output))* o_hidden2[np.newaxis].T))\n",
    "        b_output = b_output + (lr * ((error * o_output * (1 - o_output))))\n",
    "        # Hidden Layer2\n",
    "        w_hidden2 = w_hidden2 + (lr * (eh2 * o_hidden2 * (1 - o_hidden2))* o_hidden1[np.newaxis].T)\n",
    "        b_hidden2 = b_hidden2 + (lr * (eh2 * o_hidden2 * (1 - o_hidden2)))\n",
    "        # Hidden Layer1\n",
    "        w_hidden1 = w_hidden1 + (lr * (eh1 * o_hidden1 * (1 - o_hidden1))* input[idx][np.newaxis].T)\n",
    "        b_hidden1 = b_hidden1 + (lr * (eh1 * o_hidden1 * (1 - o_hidden1)))\n",
    "        \n",
    "    MSE = MSE/len(target)\n",
    "    acc = 1 - (np.sum(np.absolute(target-new_target))/len(target))\n",
    "    loss_values.append(MSE)\n",
    "    acc_values.append(acc)\n",
    "    list_w_hidden1.append(w_hidden1)\n",
    "    list_w_hidden2.append(w_hidden2)\n",
    "    list_w_output.append(w_output)\n",
    "    list_b_hidden1.append(b_hidden1)\n",
    "    list_b_hidden2.append(b_hidden2)\n",
    "    list_b_output.append(b_output)\n",
    "    print(\"epoch : \",epoch,\" | error : \",MSE,\" | acc : \",acc)\n",
    "\n",
    "acc_max   = max(acc_values)\n",
    "index_max = acc_values.index(acc_max)\n",
    "w_hidden1 = list_w_hidden1[index_max]\n",
    "w_hidden2 = list_w_hidden2[index_max]\n",
    "w_output  = list_w_output[index_max]\n",
    "b_hidden1 = list_b_hidden1[index_max]\n",
    "b_hidden2 = list_b_hidden2[index_max]\n",
    "b_output  = list_b_output[index_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "mAUsajPMHhpL",
    "outputId": "783adea5-0207-4bf5-8e85-f94f7f1c871d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot1 = plt.figure(1)\n",
    "plt.plot(loss_values)\n",
    "plt.title(\"Loss Values\")\n",
    "plt.show()\n",
    "\n",
    "plot2 = plt.figure(2)\n",
    "plt.plot(acc_values)\n",
    "plt.title(\"Accuracy Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Vs4IacSMH2FB"
   },
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    HasilPredict = []\n",
    "    for i in data:\n",
    "      # Hidden Layer1\n",
    "      o_hidden1 = np.matmul(i, w_hidden1) + b_hidden1\n",
    "      o_hidden1 = sig(o_hidden1)\n",
    "      # Hidden Layer2\n",
    "      o_hidden2 = np.matmul(o_hidden1, w_hidden2) + b_hidden2\n",
    "      o_hidden2 = sig(o_hidden2)\n",
    "      # Outpur Layer\n",
    "      o_output  = np.matmul(o_hidden2, w_output) + b_output\n",
    "      o_output  = sig(o_output)\n",
    "      HasilPredict.append(round(float(o_output)))\n",
    "    return HasilPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YIW8tu0OA3o",
    "outputId": "52334ee5-afba-458f-c53b-0e44a424255a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Result : 0\n"
     ]
    }
   ],
   "source": [
    "prediksi = predict([x_train[4]])\n",
    "print(prediksi)\n",
    "#e is 0\n",
    "#p is 1\n",
    "for i in prediksi :\n",
    "  if i == 1 :\n",
    "    print('Result : 1')\n",
    "  elif i == 0 :\n",
    "    print('Result : 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "KpkIPhxc6E2A",
    "outputId": "2838ac91-331b-44eb-fc54-552590d4a296"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Embarked  \n",
       "0        0         A/5 21171   7.2500        S  \n",
       "1        0          PC 17599  71.2833        C  \n",
       "2        0  STON/O2. 3101282   7.9250        S  \n",
       "3        0            113803  53.1000        S  \n",
       "4        0            373450   8.0500        S  \n",
       "..     ...               ...      ...      ...  \n",
       "886      0            211536  13.0000        S  \n",
       "887      0            112053  30.0000        S  \n",
       "888      2        W./C. 6607  23.4500        S  \n",
       "889      0            111369  30.0000        C  \n",
       "890      0            370376   7.7500        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.7613636363636364, 0.6666666666666666, 0.8333333333333334, 0.97165991902834, 1.0]\n",
      "[0.0, 0.7613636363636364, 0.6666666666666666, 0.8333333333333334, 0.97165991902834, 1.0]\n",
      "[0.0, 0.5681818181818182, 0.6666666666666666, 0.8333333333333334, 0.97165991902834, 1.0]\n",
      "[0.0, 0.5681818181818182, 0.16666666666666666, 0.8333333333333334, 0.97165991902834, 1.0]\n",
      "[0.0, 0.5681818181818182, 0.16666666666666666, 0.6666666666666666, 0.97165991902834, 1.0]\n",
      "[0.0, 0.5681818181818182, 0.16666666666666666, 0.6666666666666666, 0.6072874493927125, 1.0]\n",
      "[0.0, 0.5681818181818182, 0.16666666666666666, 0.6666666666666666, 0.6072874493927125, 0.0]\n",
      "[0.0, 0.5681818181818182, 0.16666666666666666, 0.6666666666666666, 0.46558704453441296, 0.0]\n",
      "[0.0, 0.5681818181818182, 0.16666666666666666, 0.6666666666666666, 0.708502024291498, 0.0]\n",
      "[0.0, 0.3409090909090909, 0.16666666666666666, 0.6666666666666666, 0.708502024291498, 0.0]\n",
      "[0.0, 0.5227272727272727, 0.16666666666666666, 0.0, 0.708502024291498, 0.0]\n",
      "[0.0, 0.5227272727272727, 0.16666666666666666, 0.0, 0.7125506072874493, 0.0]\n",
      "[0.0, 0.5227272727272727, 0.16666666666666666, 0.0, 0.7165991902834008, 0.0]\n",
      "[0.0, 0.5227272727272727, 0.16666666666666666, 0.0, 0.8097165991902834, 0.0]\n",
      "[0.0, 0.6818181818181818, 0.16666666666666666, 0.0, 0.8097165991902834, 0.0]\n",
      "[0.0, 0.6818181818181818, 0.16666666666666666, 0.0, 0.8097165991902834, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.16666666666666666, 0.0, 0.8097165991902834, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.16666666666666666, 0.0, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.16666666666666666, 0.16666666666666666, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.16666666666666666, 0.6666666666666666, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.16666666666666666, 0.8333333333333334, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.16666666666666666, 0.0, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.0, 0.0, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.0, 0.16666666666666666, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.0, 0.3333333333333333, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.0, 0.5, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.0, 0.6666666666666666, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.3333333333333333, 0.6666666666666666, 1.214574898785425, 1.0]\n",
      "[1.0, 0.6818181818181818, 0.8333333333333334, 0.6666666666666666, 1.214574898785425, 1.0]\n",
      "[1.0, 0.022727272727272728, 0.16666666666666666, 0.6666666666666666, 1.214574898785425, 1.0]\n",
      "[1.0, 0.022727272727272728, 0.16666666666666666, 0.0, 1.214574898785425, 1.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 1.214574898785425, 1.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 10.666666666666666]\n",
      "[0.0, 0.3409090909090909, 0.0, 0.0, 0.0, 10.666666666666666]\n",
      "[0.0, 0.3409090909090909, 0.0, 0.0, 0.016194331983805668, 10.666666666666666]\n",
      "[0.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3_7\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[0.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[0.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[0.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[0.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[0.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[0.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[1.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[1.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[1.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[1.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[1.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n",
      "[1.0, 0.3409090909090909, 0.0, 0.6666666666666666, 0.008097165991902834, 10.666666666666666]\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter.ttk import Combobox\n",
    "from tkinter import messagebox\n",
    "\n",
    "\n",
    "class Test:\n",
    "    def __init__(self, tk):\n",
    "        self.var = StringVar()\n",
    "        self.data = (0, 1)\n",
    "        self.lb0 = Label(tk,  text = 'MULTILAYER PERCEPTRON PREDIKSI KESELAMATAN PENUMPANG TITANIC',\n",
    "                         font = (\"Times\",12)).place(x=15,y=0)\n",
    "        self.lb1 = Label(tk,  text = 'Sex',font = (\"Times\",9)).place(x=5,y=50)\n",
    "        self.lb2 = Label(tk,  text = 'Age',font = (\"Times\",9)).place(x=5,y=75)\n",
    "        self.lb3 = Label(tk,  text = 'SibSp',font = (\"Times\",9)).place(x=5,y=100)\n",
    "        self.lb4 = Label(tk,  text = 'Parch',font = (\"Times\",9)).place(x=5,y=125)\n",
    "        self.lb5 = Label(tk,  text = 'Fare',font = (\"Times\",9)).place(x=5,y=150)\n",
    "        self.lb6 = Label(tk,  text = 'Embarked',font = (\"Times\",9)).place(x=5,y=175)\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        self.cb1 = Combobox(tk, values=self.data,font = (\"Times\",9), width=17)\n",
    "        self.cb1.place(x=80, y=50)\n",
    "        self.e2  = Entry(tk,font = (\"Times\",9) )\n",
    "        self.e2.place(x=80,y=75)\n",
    "        self.e3  = Entry(tk,font = (\"Times\",9) )\n",
    "        self.e3.place(x=80,y=100)\n",
    "        self.e4  = Entry(tk,font = (\"Times\",9) )\n",
    "        self.e4.place(x=80,y=125)\n",
    "        self.e5  = Entry(tk,font = (\"Times\",9) )\n",
    "        self.e5.place(x=80,y=150)\n",
    "        self.e6  = Entry(tk,font = (\"Times\",9) )\n",
    "        self.e6.place(x=80,y=175)\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        self.b1  = Button(tk, text=\"Prediksi\",font = (\"Times\",9), command=self.select).place(x=300, y=250, anchor=CENTER)\n",
    "        self.lb7 = Label(tk,  text = 'Hasil', font = (\"Times\",9))\n",
    "        self.lb7.place(x=300, y=300, anchor=CENTER)\n",
    "        \n",
    "    def select(self):\n",
    "        data   = []\n",
    "        value1 = (float(self.cb1.get())-minn[0])/(maxx[0]-minn[0])\n",
    "        #messagebox.showinfo(\"Warn\", \"You selected \" + value)\n",
    "        value2 = (float(self.e2.get())-minn[1])/(maxx[1]-minn[1])\n",
    "        value3 = (float(self.e3.get())-minn[2])/(maxx[2]-minn[2])\n",
    "        value4 = (float(self.e4.get())-minn[3])/(maxx[3]-minn[3])\n",
    "        value5 = (float(self.e5.get())-minn[4])/(maxx[4]-minn[4])\n",
    "        value6 = (float(self.e6.get())-minn[5])/(maxx[5]-minn[5])\n",
    "        data.append(value1)\n",
    "        data.append(value2)\n",
    "        data.append(value3)\n",
    "        data.append(value4)\n",
    "        data.append(value5)\n",
    "        data.append(value6)\n",
    "        HasilPredict = []\n",
    "        print(data)\n",
    "        for i in data:\n",
    "            # Hidden Layer1\n",
    "            o_hidden1 = np.matmul(data, w_hidden1) + b_hidden1\n",
    "            o_hidden1 = sig(o_hidden1)\n",
    "            # Hidden Layer2\n",
    "            o_hidden2 = np.matmul(o_hidden1, w_hidden2) + b_hidden2\n",
    "            o_hidden2 = sig(o_hidden2)\n",
    "            # Outpur Layer\n",
    "            o_output  = np.matmul(o_hidden2, w_output) + b_output\n",
    "            o_output  = sig(o_output)\n",
    "            HasilPredict.append(round(float(o_output)))\n",
    "        for i in HasilPredict:\n",
    "            if i == 1 :\n",
    "                a = 'Selamat'\n",
    "            elif i == 0 :\n",
    "                a = 'Tewas'\n",
    "        self.lb7.config(text=a)\n",
    "tk = Tk()\n",
    "tk.geometry(\"600x350\")\n",
    "tk.title(\"MULTILAYER PERCEPTRON\")\n",
    "tt = Test(tk)\n",
    "tk.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
